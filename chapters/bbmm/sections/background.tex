%!TEX root=main.tex
\section{Background}

\paragraph{Notation.}
$\bX$ will denote a set of $n$ training examples in $d$ dimensions, or equivalently an $n \times d$ matrix where the $i^{\text{th}}$ row (denoted $\bx_{i}$) is the $i^\text{th}$ training example.
$\by$ denotes the training labels.
$k(\bx, \bx')$ denotes a \emph{kernel function}, and $\bK_{\bX\bX}$ denotes the matrix containing all pairs of kernel entries, i.e. $[\bK_{\bX\bX}]_{ij} = k(\bx_{i}, \bx_{j})$.
$\bk_{\bX\bx^{*}}$ denotes kernel values between training examples and a test point $\bx^{*}$, e.g. $[\bk_{\bX\bx^{*}}]_{i} = k(\bx_{i}, \bx^{*})$.
A hat denotes an added diagonal: $\trainK = \bK_{\bX\bX} + \sigma^{2}I$.

\paragraph{A Gaussian process} (GP) is a kernel method that defines a full distribution over the function being modeled, $f(\bx) \sim \mathcal{GP} \left( \mu(\bx), k(\bx,\bx^{\prime}) \right)$.
Popular kernels include the RBF kernel, $k(\bx, \bx^{\prime}) = s\exp\left(-(\Vert \bx - \bx^{\prime} \Vert)/(2\ell^{2})\right)$ and the Mat\'ern family of kernels \cite{rasmussen2006gaussian}.

\paragraph{Predictions with a Gaussian process.}
Predictions with a GP are made utilizing the \emph{predictive posterior distribution}, $p(f(\bx^{*})\mid\bX,\by)$. Given two test inputs $\bx^{*}$ and $\bx^{*\prime}$, the predictive mean for $\bx^{*}$ and the predictive covariance between $\bx^{*}$ and $\bx^{*\prime}$ are given by:
%
\begin{align}
  \mu_{f \mid \dset}(\bx^*) = \mu(\bx^*) + \bk_{\bX \bx^*}^\top \trainK^{-1} \by,
  &&&&
  k_{f\mid\dset}(\bx^*, \bx^{*\prime}) = k_{\bx^{*} \bx^{*\prime}} - \bk_{\bX \bx^{*}}^\top \trainK^{-1} \bk_{\bX \bx^{*\prime}},
    \label{eq:pred_mean_covar}
\end{align}
%
\paragraph{Training a Gaussian process.}
Gaussian processes depend on a number of \emph{hyperparameters} $\theta$.
Hyperparameters may include the likelihood noise, kernel lengthscale, inducing point locations \cite{titsias2009variational}, or neural network parameters for deep kernel learning \cite{wilson2016deep}.
These parameters are commonly learned by minimizing or sampling via the \emph{negative log marginal likelihood}, given (with derivative) by
%
\begin{equation}
  \loglik (\theta \! \mid \! \bX, \by) \propto \log \left\vert \trainK \right\vert - \by^{\top}\trainK^{-1}\by,
  \:\:\:
  \frac{dL}{d\theta} = \by^{\top} \! \trainK^{-1}\frac{d\trainK}{d\theta}\trainK^{-1}\by + \tr{\trainK^{-1}\frac{d\trainK}{d\theta}} \label{eq:log_lik_and_deriv}.
\end{equation}
