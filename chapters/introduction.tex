\chapter{Introduction}
\label{chapt:introduction}

%Machine learning hype <- success in many different areas.
%Success in many different areas <- advances in algorithms.
%Advances of algorithms <- both in terms of raw potential and in terms of the practical.
%The best algorithms are ones that offer both potential and practicality.
%No one algorithm is perfect <- we need a quiver of different possible algorithms.

%Don't talk about advances.
%Find a lead in to discuss algorithms.

%At this point in machine learning we have several sets of algorithms.

%Questions we need to answer:
%- Why is it important to have multiple algorithms?
%- What kind of algorithms are we looking for?

%Of course, no one algorithm is good at every possible task.
%For example, on many computer vision tasks it is commonly assumed there will be some sort of convolutional layers.
%On many Kaggle competitions, a majority of winning submissions utilize random forests.
%Therefore, it is arguably good to have a variety of possible algorithms.



%Neural networks.

Rapid advances in machine learning have led to numerous empirical successes and wide-scale adoption in many application domains.
%Here we will highlight two broad categories of methodological innovation that have contributed to this surge.
Researchers have improved the {\bf predictive capabilities} of machine learning models.
Algorithms are now able to achieve superhuman performance on complex tasks like object recognition \cite{} and strategy game-playing \cite{}.
There have also been important strides making these predictions more risk-aware \cite{}, interpretable \cite{}, and societally equitable \cite{}.
At the same time, the machine learning community has addressed many {\bf pragmatic concerns} around computational efficiency and easy-of-use.
Models which used to require several weeks of training can now be trained in under an hour \cite{}.
Transfer learning techniques \cite{} and high-quality software frameworks have additionally made it easier for practitioners to rapidly-prototype new models.
While many other factors have contributed to the machine learning surge, we will limit our focus to these two categories.
Ever-increasing predictive capabilities have opened up new possibilities, while pragmatic improvements have accelerated the rate of innovation and adoption.

Arguably, the machine learning algorithms which have had the broadest impact are the ones that seamlessly offer \emph{both} predictive potential and practicality.
Deep neural networks perhaps best exemplify this trend.
Recent innovations in
network architecture \citep[e.g.][]{krizhevsky2012imagenet,he2016deep,vaswani2017attention,devlin2018bert,huang2019convolutional},
optimization \citep[e.g.][]{hochreiter1997flat,bottou2010large,ioffe2015batch,izmailov2018averaging},
and theoretical understanding \citep[e.g.][]{keskar2016large,zhang2016understanding,}
have led to massive performance improvements on increasingly complex vision and natural language tasks.
Moreover, these innovations have been complemented by
the effective use of specialty compute hardware (such as GPUs and TPUs),
the introduction of automatic differentiation \citep[e.g.][]{paszke2017automatic},
and the development of of several easy-to-use software implementations~\citep[e.g.][]{jia2014caffe,chen2015mxnet,abadi2016tensorflow,paszke2019pytorch}.
These practical advances make it easy for practitioners to experiment with and rapidly prototype new deep learning models, which has undoubtedly contributed to research innovations and its wide-spread adoption \cite{goodfellow2016deep}.

Gradient-boosted trees are another algorithm class with a similar powerful-and-practical story.
Since their inception \cite{friedman2001greedy,friedman2002stochastic}, gradient boosted trees have excelled in many applications \citep[e.g.][]{richardson2007predicting,burges2010ranknet,li2010robust}.
The predictive power of these models is a product of several key attributes: for example, their remarkable generalization properties \citep{freund1997decision,schapire2013boosting} and their ability to handle incomplete features \cite{friedman2001greedy}.
Equally important, these models can be simple and computational efficient, in large part due to specialty parallel algorithms \citep[e.g.][]{panda2009planet,tyree2011parallel,ke2017lightgbm} and easy-to-use software implementations such as XGBoost \cite{chen2016xgboost}.
These advantages have made gradient-boosted decision trees a workhorse algorithm for many practitioners in a wide variety of application domains.
According to the most recent survey collected by Kaggle \cite{kaggle2019kaggle}, $75\%$ of the responding data scientists regularly use gradient-boosted decision trees and the XGBoost software.

However, for many machine learning algorithms there is still a trade-off between predictive potential and its practical limitations.
The focus of this thesis is {\bf Gaussian process models} (GPs), which perhaps best exemplify this tension.
Within the machine learning community, GPs have been well-regarded as a powerful model class with many desirable properties---such as calibrated uncertainty estimates and interpretable model priors.
Recent work on hierarchical modelling \citep[e.g.][]{damianou2013deep} and scalability \citep[e.g.][]{wilson2015kernel} have furthered their applicability to increasingly complex datasets.
However, Gaussian processes have historically not scaled well to large datasets, and the tools most commonly used for inference do not effectively utilize modern compute hardware.
Scalable approximations can remedy these concerns to some extent, yet such approximations can sometimes bias the model's predictions \cite{turner2011two,bauer2016understanding}.
Finally, new models require significant implementation, as simple modifications like an additional output dimension might require different learning and inference procedures.
These practical considerations hinder the adoption of GP models, while also limiting researchers' abilities to rapidly-prototype and make new developments.
This thesis aims to address these limitations so that Gaussian processes can be powerful-\emph{and}-practical models.

% Even as Moore's law runs out, specialty hardware

\section{Benefits and Use Cases of Gaussian Processes Models}

Before addressing these issues, it is worth discussing why Gaussian processes are an invaluable model class in domains such as blackbox optimization \cite{snoek2012practical}, robotics \cite{deisenroth2011pilco}, and health care \cite{schulam2015framework}:
\begin{enumerate}
  \item {\bf Closed-form marginalization over hypotheses.}
    Many predictive machine learning algorithms (such as neural networks) construct a single predictive model by optimizing over thousands or millions of parameters.
    Gaussian processes on the other hand marginalize over all possible predictive models $f(\cdot)$:
    \[
      p_\text{GP} ( y \mid \bx ) = \int_{f(\cdot)} p( y \mid \bx, f(\cdot)) \: p(f(\cdot)) \: \intd f(\cdot).
    \]
    (See \cref{sec:gps} for more details).
    As a result, the predictions incorporate modelling uncertainty are are less prone to overfitting \cite{rasmussen2006gaussian}.

  \item {\bf Well-calibrated uncertainty estimates.}
    The output of a Gaussian process is a predictive \emph{distribution}, which incorporates both modelling uncertainty (e.g. how many different models could fit the data) and data uncertainty (e.g. how noisy are the training data).
    Consequentially, the predictive uncertainties tend to be very well calibrated to the data distribution.

  \item {\bf A flexible language for encoding prior knowledge.}
    A Gaussian process' generalization to unseen data is almost entirely determined by its modelling priors.
    Crucially, the modelling priors of GP directly encode functional properties---such as smoothness, periodicity, or monotonicity---rather than beliefs about certain parameters.
    These functional properties are determined by the choice of \emph{kernel function}, which can be easily composed to express complex priors (see \cref{sec:common_kernels}).
    With the appropriate choice of prior, it is possible to generalize on datasets with as few as 10 observations \citep[e.g.]{rasmussen2006gaussian,gardner2017discovering}.
    Several recent works have simplified the task of constructing appropriate kernels, either through composition \citep{duvenaud2013structure} or through differentiable learning \citep{wilson2013gaussian}.

  \item {\bf Interpretable predictions.}
    The predictions from Gaussian processes (see \cref{eqn:predictive_mean,eqn:predictive_var}) are not only expressive and powerful; they are also very intuitive.
    If we view the GP's kernel function as a similarity/distance measure between two points, then the prediction at a given point $\bx$ is simply an interpolation of nearby training points.
    The prediction's confidence interval is tight when $\bx$ is close to training dataset points, and large when $\bx$ is too far from points for accurate interpolation.
\end{enumerate}

The benefits listed above are obviously applicable to the ``small data'' regime, where priors and marginalization are critical for meaningful predictive performance.
However, it is worth noting that many of these desirable properties also apply to large data regimes as well.
Gaussian processes (with certain kernels) are universal approximators \cite{micchelli2006universal}, and their modelling capacity increases with the amount of available training data.
Larger datasets make it possible to use more powerful families of covariance functions \citep{wilson2013gaussian,wilson2016deep,benton2019function}, which is especially useful for extrapolating on complex spatial-temporal data.
Moreover, using Gaussian processes within hierarchical models \cite{wilson2016deep,salimbeni2017doubly,jankowiak2020deep}

\section{Practical Concerns regarding Gaussian Processes Models}

\section{Outline of Contributions}

This thesis proposes several methods to alleviate these issues without sacrificing the predictive power or desirable properties of Gaussian processes.
At the heart of these methods is a unified learning/inference framework that better utilizes modern compute hardware and simplifies implementation efforts.
Taking inspiration from neural networks, we restrict our computational procedures to matrix multiplication and element-wise operations, finding opportunities to unify or batch operations wherever possible.
\gp{CONTINUE}
% In fact, we are not simply going to take inspiration from Neural networks, we are going to directly exploit those tools

%\paragraph{Preventing catastrophic failure.}

%\paragraph{Improved predictive pipelines.}

%\paragraph{Detecting anomalous inputs.}
%Machine learning models will only generalize to data that are sufficiently similar to the training data.
%If a model encounters \emph{out-of-distribution} (OOD) inputs -- inputs that deviate from the distribution of training data -- its predictions are likely to be erroneous or nonsensical \cite{begoli2019uncertainty,jiang2012calibrating}.
%%This may occur if the model is used in scenarios that experience covariate shift \cite{sugiyama2007covariate} or if the model encounters previously-unseen categories of data \cite{yu2017occ,hassen2018openset}.
%%Such scenarios are examples of \emph{out-of-distribution} (OOD) inputs.
%This phenomenon is illustrated in \cref{fig:ood_teaser}, which displays predictions from a neural network trained to predict prices of middle-class houses in Kentucky.
%The model is able to make sensible predictions on other Kentucky houses (left and center-left images).
%At the same time, the model vastly underestimates the price of a California mansion (center-right) and predicts and absurdly large price for a chair (right), as these inputs are not similar to any of the training set inputs.
%This is because the range of predicted prices for the out-of-distribution matches the range of Kentucky housing prices.
%A practitioner would see that the predictions are well within the model's expected output values and would be unaware that these predictions are nonsensical given the supplied inputs.

%Well-modeled uncertainty estimates can to identify potentially anomalous data and prevent such erroneous predictions.
%In this example, \gp{finish}

%\paragraph{A principled exploration/exploitation tradeoff.}

%\paragraph{Interpretability and trustworthiness.}
%Good uncertainty estimates can provide a valuable extra bit of information to users of machine learning models when predictions may otherwise be difficult to interpret.
%As machine learning algorithms become increasingly complex, they also appear more ``black box'' to users of such systems.
%This presents several challenges, especially for models that are used to aid human decision makers in domains such as medicine, finance, and policy \gp{cite}.

%For such circumstances it is therefore desirable for predictions to be understandable or interpretable \gp{cite LIME, saliency, etc.}.
%There are many definitions for what constitutes a good ``explanation'' of black-box predictions, coming from policy makers \gp{cite gdpr, etc} and the research community \gp{cite} alike.
%Though there are disagreements between these various sources, a well-calibrated uncertainty estimate is typically seen as a bare-minimum requirement for an interpretable prediction \gp{cite}.
%Most humans -- even if they are unable to perform simple inferences \cite{gigerenzer2003simple} -- have natural intuition for interpreting confidence estimates as event-occurrence frequencies \cite{cosmides1996humans,hoffrage1998using}.
%Therefore, well-calibrated confidence estimates from ML models can be easily interpreted by users.
%Moreover, the presence of uncertainty estimates can affect a user's trust in a machine learning model.
%In a study by \citet{zhou2017effects}, humans were asked to plan a budget for construction tasks based on information provided by a machine learning model.
%Some participants received both predictions and confidence intervals from the machine learning model, while other users only received the predictions.
%On tasks with low-to-moderate cognitive overhead, participants who saw uncertainty scores reported higher levels of trust in the machine learning model.
